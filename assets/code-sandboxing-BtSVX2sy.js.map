{"version":3,"file":"code-sandboxing-BtSVX2sy.js","sources":["../../src/content/blog/code-sandboxing.md?raw"],"sourcesContent":["export default \"---\\nid: ai-coding-sandboxes-2026\\ntitle: \\\"The Digital Cage: How AI Agents Run Code Safely\\\"\\ndate: 2026-01-01\\nreadTime: 8 min\\nexcerpt: \\\"AI agents are writing and executing code at light speed. But how do we stop them from deleting our files? We dive into the kernel-level tricks and sandbox tech used by Claude Code, Cursor, and Devin.\\\"\\ntags: [\\\"AI\\\", \\\"Cybersecurity\\\", \\\"DevOps\\\", \\\"Software Engineering\\\"]\\n---\\n\\nImagine giving a hyper-intelligent, slightly clumsy intern full access to your terminal. They‚Äôre fast, they know every library, and they work for free‚Äîbut every now and then, they might try to `rm -rf /` because they hallucinated it was a good way to \\\"clear some space.\\\" üòÖ\\n\\nThis is the reality of AI coding agents. To make them useful, we have to let them execute code. To make them safe, we have to put them in a **sandbox**.\\n\\nIn this article, we‚Äôll explore the different ways modern AI tools create these \\\"digital cages\\\" to keep your system safe while the AI works its magic. ü™Ñ\\n\\n---\\n\\n## Why a Simple \\\"Allow-List\\\" Isn't Enough\\n\\nEarly AI tools relied on simple permission prompts: *\\\"The AI wants to run this command. Allow? (Y/N)\\\"*.\\n\\nBut as agents become more autonomous, hitting \\\"Y\\\" five hundred times a day isn't just annoying‚Äîit‚Äôs dangerous. **Prompt Injection** attacks can trick an AI into running malicious commands hidden in a README file or a comment. We need a way to let the AI run code where even if it *wants* to be bad, the operating system simply says \\\"No.\\\" üõ°Ô∏è\\n\\n## 1. The macOS Standard: Seatbelt üèéÔ∏è\\n\\nIf you‚Äôre using **Claude Code** or the latest **Cursor IDE** on a Mac, you are likely using a technology called **Seatbelt**.\\n\\nSeatbelt is a kernel-level security framework that Apple uses for its own system apps. Instead of just blocking specific commands, it uses a **Sandbox Profile Language (SBPL)**‚Äîa Lisp-based configuration‚Äîto define exactly what a process can touch.\\n\\n### How it works for AI:\\n\\nWhen an agent runs a bash command, the tool wraps that process in a Seatbelt profile.\\n\\n* **Filesystem:** The AI can only see your project folder. Your `~/.ssh` or `~/Documents` folders become invisible. üëª\\n* **Network:** It can‚Äôt \\\"phone home\\\" to an attacker‚Äôs server unless you‚Äôve explicitly whitelisted that domain.\\n\\nFor developers, you can actually see this in action by watching the system logs for denials:\\n\\n```bash\\nlog stream --style compact --predicate 'sender == \\\"Sandbox\\\" AND eventMessage contains \\\"deny\\\"'\\n\\n```\\n\\n## 2. Linux Isolation: Landlock & Bubblewrap ü´ß\\n\\nOn Linux, AI agents use a similar strategy but with different tools.\\n\\n* **Landlock:** A relatively new Linux Security Module (LSM) that allows a process (like a coding agent) to restrict its own access to the filesystem. It‚Äôs \\\"unprivileged,\\\" meaning it doesn't need root to secure itself.\\n* **Bubblewrap:** This is often the engine behind the scenes. It uses **Namespaces** to create a private view of the computer for the AI, giving it its own temporary `/tmp` and restricting it to the workspace.\\n\\n## 3. The \\\"Hardware\\\" Approach: MicroVMs üèóÔ∏è\\n\\nWhile Seatbelt and Landlock are great for local tools, autonomous agents like **Devin** or hosted platforms like **E2B** go a step further. They use **MicroVMs** (specifically **Firecracker**).\\n\\nUnlike a container (Docker), which shares the same \\\"brain\\\" (kernel) as the host, a MicroVM has its own dedicated kernel. It boots in milliseconds and provides a total hardware-level boundary.\\n\\n* **Pros:** Even if the AI finds a kernel exploit, it‚Äôs still trapped inside a tiny, throwaway virtual computer.\\n* **Cons:** Slightly more resource-intensive than native OS sandboxing.\\n\\n## 4. Deep Dive: Claude Code's Sandbox Strategy ü§ñ\\n\\nClaude Code is a great example of **Hybrid Isolation**. It doesn't just rely on one layer; it uses a \\\"Defense in Depth\\\" strategy:\\n\\n1. **System Primitives:** On Mac, it uses **Seatbelt**. On Linux, it uses **Bubblewrap**.\\n2. **Network Proxy:** Instead of letting the AI talk directly to the internet, Claude Code routes traffic through a local proxy. If the AI tries to `curl` a suspicious URL, the proxy catches it and asks *you* for permission.\\n3. **The \\\"Escape Hatch\\\":** Sometimes, the sandbox is *too* strict (e.g., when you need to install a global package). In these cases, Claude will ask to use a flag like `--dangerously-disable-sandbox`. **Pro-tip:** Never use this unless you absolutely trust the code the AI just wrote! ‚ö†Ô∏è\\n\\n---\\n\\n## Summary & Key Takeaways üìù\\n\\nSandboxing has moved from being an \\\"extra feature\\\" to the **foundation** of AI-assisted coding. Here is the quick cheat sheet:\\n\\n| Technique | Used By | Best For... |\\n| --- | --- | --- |\\n| **Seatbelt** | Claude Code (Mac), Cursor | Local security on macOS with zero overhead. |\\n| **Landlock / Bwrap** | Claude Code (Linux) | High-performance isolation on Linux. |\\n| **MicroVMs** | Devin, E2B | Maximum security for autonomous, untrusted agents. |\\n| **Docker** | Open Interpreter, Replit | Cross-platform consistency and \\\"disposable\\\" environments. |\\n\\n### Key Takeaways:\\n\\n* **Default to Sandbox:** Always run AI agents with the sandbox enabled to prevent data exfiltration.\\n* **Watch the Logs:** Use system tools like `log stream` (Mac) to see when your agent is hitting security boundaries.\\n* **Filesystem First:** The most important rule of AI sandboxing is restricting the agent to your **workspace folder only**.\\n\\nAs AI agents get smarter, our \\\"cages\\\" will need to get stronger. But with tools like Seatbelt and Firecracker, we can let the AI build our apps without worrying about it accidentally building a back-door into our systems. üöÄ\\n\""],"names":["codeSandboxing"],"mappings":"AAAA,MAAAA,EAAe;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;"}